{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Eye Of The Typer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from datetime import datetime, timedelta\n",
    "from pprint import pprint\n",
    "\n",
    "import polars as pl\n",
    "import rerun as rr\n",
    "import cv2 as cv\n",
    "\n",
    "from the_eye_of_the_typer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %env set THE_EYE_OF_THE_TYPER_DATASET_PATH\n",
    "df = read_participant_characteristics()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = [Participant.create(**row) for row in df.iter_rows(named=True)]\n",
    "\n",
    "print(\"Participants:\", len(participants), end=\"\\n\\n\")\n",
    "pprint(participants[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = participants[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.init(\"EOTT\", recording_id=p.participant_id, spawn=True)\n",
    "rr.log(\n",
    "    \"participant\",\n",
    "    rr.TextDocument(\n",
    "        \"\\n\".join(f\"[{key}]\\n{value}\\n\" for key, value in p.to_dict().items())\n",
    "    ),\n",
    "    timeless=True,\n",
    ")\n",
    "\n",
    "screen_cap: cv.VideoCapture | None = None\n",
    "webcam_cap: cv.VideoCapture | None = None\n",
    "\n",
    "screen_width = p.display_width\n",
    "screen_height = p.display_height\n",
    "\n",
    "if p.screen_recording is not None:\n",
    "    screen_cap = cv.VideoCapture(str(p.screen_recording_path))\n",
    "    screen_scale_factor = 2\n",
    "    screen_width = screen_width // screen_scale_factor\n",
    "    screen_height = screen_height // screen_scale_factor\n",
    "\n",
    "rr.log(\n",
    "    f\"screen\",\n",
    "    rr.Boxes2D(\n",
    "        sizes=[[screen_width, screen_height]],\n",
    "        centers=[[screen_width / 2, screen_height / 2]],\n",
    "    ),\n",
    "    timeless=True,\n",
    ")\n",
    "\n",
    "rr.log(\n",
    "    \"participant/pupil/left/tobii\",\n",
    "    rr.SeriesLine(color=[255, 255, 0], width=1, name=\"left pupil diameter (tobii)\"),\n",
    "    timeless=True,\n",
    ")\n",
    "rr.log(\n",
    "    \"participant/pupil/right/tobii\",\n",
    "    rr.SeriesLine(color=[255, 0, 255], width=1, name=\"right pupil diameter (tobii)\"),\n",
    "    timeless=True,\n",
    ")\n",
    "\n",
    "timeline_df = get_timeline(p)\n",
    "\n",
    "frame_index: int\n",
    "source_name: Literal[\"tobii\", \"log\", \"screen\", \"webcam\"]\n",
    "offset_time: timedelta\n",
    "study_name: str | None\n",
    "study_index: int | None\n",
    "for (\n",
    "    frame_index,\n",
    "    offset_time,\n",
    "    source_name,\n",
    "    study_name,\n",
    "    study_index,\n",
    ") in timeline_df.iter_rows():\n",
    "    rr.set_time_sequence(f\"{source_name}_index\", frame_index)\n",
    "    rr.set_time_seconds(\"capture_time\", offset_time.total_seconds())\n",
    "\n",
    "    match source_name:\n",
    "        case \"screen\" if screen_cap is not None:\n",
    "            rr.set_time_seconds(\n",
    "                \"screen_time\", screen_cap.get(cv.CAP_PROP_POS_MSEC) / 1_000\n",
    "            )\n",
    "\n",
    "            assert p.screen_recording is not None\n",
    "            assert p.screen_offset is not None\n",
    "\n",
    "            success, frame = screen_cap.read()\n",
    "\n",
    "            if not success or frame_index % 4 != 0:\n",
    "                continue\n",
    "\n",
    "            frame = cv.resize(frame, (screen_width, screen_height))\n",
    "            frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "            rr.log(\"screen\", rr.Image(frame))\n",
    "\n",
    "        case \"tobii\":\n",
    "            entry: TobiiEntry = p.tobii_gaze_predictions.row(frame_index, named=True)\n",
    "\n",
    "            for eye in (\"left\", \"right\"):\n",
    "                if entry[f\"{eye}_gaze_point_validity\"]:\n",
    "                    x, y = entry[f\"{eye}_gaze_point_on_display_area\"]\n",
    "                    rr.log(\n",
    "                        f\"screen/gazepoint/{eye}/tobii\",\n",
    "                        rr.Points2D(\n",
    "                            [[x * screen_width, y * screen_height]],\n",
    "                            colors=[[0, 0, 255]],\n",
    "                            radii=[1],\n",
    "                        ),\n",
    "                    )\n",
    "                else:\n",
    "                    rr.log(\n",
    "                        f\"screen/gazepoint/{eye}/tobii\",\n",
    "                        rr.Clear(recursive=True),\n",
    "                    )\n",
    "\n",
    "                if (\n",
    "                    entry[f\"{eye}_pupil_validity\"]\n",
    "                    and entry[f\"{eye}_pupil_diameter\"] > 0\n",
    "                ):\n",
    "                    rr.log(\n",
    "                        f\"participant/pupil/{eye}/tobii\",\n",
    "                        rr.Scalar(entry[f\"{eye}_pupil_diameter\"]),\n",
    "                    )\n",
    "                else:\n",
    "                    rr.log(f\"participant/pupil/{eye}/tobii\", rr.Clear(recursive=True))\n",
    "\n",
    "        case \"log\":\n",
    "            level_map = {\n",
    "                \"start\": rr.TextLogLevel.CRITICAL,\n",
    "                \"stop\": rr.TextLogLevel.ERROR,\n",
    "                \"mouse\": rr.TextLogLevel.TRACE,\n",
    "                \"scroll\": rr.TextLogLevel.DEBUG,\n",
    "                \"click\": rr.TextLogLevel.WARN,\n",
    "                \"text\": rr.TextLogLevel.INFO,\n",
    "            }\n",
    "            entry: LogEntry = p.user_interaction_logs.row(frame_index, named=True)\n",
    "            event_type = entry[\"event\"]\n",
    "            if event_type is not None:\n",
    "                rr.log(\n",
    "                    \"participant/event\",\n",
    "                    rr.TextLog(entry[\"event\"], level=level_map[entry[\"event\"]]),\n",
    "                )\n",
    "\n",
    "            match event_type:\n",
    "                case \"mouse\":\n",
    "                    rr.log(\n",
    "                        \"screen/mouse\",\n",
    "                        rr.Points2D(\n",
    "                            [\n",
    "                                [\n",
    "                                    entry[\"screen_x\"] / screen_scale_factor,\n",
    "                                    entry[\"screen_y\"] / screen_scale_factor,\n",
    "                                ]\n",
    "                            ],\n",
    "                            colors=[(255, 255, 0)],\n",
    "                            radii=[1],\n",
    "                        ),\n",
    "                    )\n",
    "\n",
    "# end of logging\n",
    "if screen_cap is not None:\n",
    "    screen_cap.release()\n",
    "\n",
    "if webcam_cap is not None:\n",
    "    webcam_cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
