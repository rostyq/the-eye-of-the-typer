{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Eye Of The Typer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Literal, Iterator\n",
    "from datetime import datetime, timedelta\n",
    "from pprint import pprint\n",
    "\n",
    "import polars as pl\n",
    "import rerun as rr\n",
    "import cv2 as cv\n",
    "\n",
    "from the_eye_of_the_typer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %env set THE_EYE_OF_THE_TYPER_DATASET_PATH\n",
    "df = read_participant_characteristics()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = [Participant.create(**row) for row in df.iter_rows(named=True)]\n",
    "\n",
    "print(\"Participants:\", len(participants), end=\"\\n\\n\")\n",
    "pprint(participants[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = participants[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.init(\"EOTT\", recording_id=p.participant_id, spawn=True)\n",
    "rr.log(\n",
    "    \"participant\",\n",
    "    rr.TextDocument(\n",
    "        \"\\n\".join(f\"[{key}]\\n{value}\\n\" for key, value in p.to_dict().items())\n",
    "    ),\n",
    "    timeless=True,\n",
    ")\n",
    "\n",
    "screen_cap: cv.VideoCapture | None = None\n",
    "webcam_cap: cv.VideoCapture | None = None\n",
    "webcam_path: Path | None = None\n",
    "webcam_paths: Iterator[Path] | None = None\n",
    "webcam_aux: int = 0\n",
    "\n",
    "screen_width = p.display_width\n",
    "screen_height = p.display_height\n",
    "\n",
    "if p.screen_recording is not None:\n",
    "    screen_cap = cv.VideoCapture(str(p.screen_recording_path))\n",
    "    screen_scale_factor = 2\n",
    "    screen_width = screen_width // screen_scale_factor\n",
    "    screen_height = screen_height // screen_scale_factor\n",
    "\n",
    "rr.log(\n",
    "    f\"screen\",\n",
    "    rr.Boxes2D(\n",
    "        sizes=[[screen_width, screen_height]],\n",
    "        centers=[[screen_width / 2, screen_height / 2]],\n",
    "    ),\n",
    "    timeless=True,\n",
    ")\n",
    "\n",
    "rr.log(\n",
    "    \"participant/pupil/left/tobii\",\n",
    "    rr.SeriesLine(name=\"left pupil diameter (tobii)\", color=(255, 255, 0), width=1),\n",
    "    timeless=True,\n",
    ")\n",
    "rr.log(\n",
    "    \"participant/pupil/right/tobii\",\n",
    "    rr.SeriesLine(name=\"right pupil diameter (tobii)\", color=(255, 0, 255), width=1),\n",
    "    timeless=True,\n",
    ")\n",
    "\n",
    "timeline_df = get_timeline(p)\n",
    "\n",
    "frame_index: int\n",
    "source_name: Literal[\"tobii\", \"log\", \"screen\", \"webcam\"]\n",
    "offset_time: timedelta\n",
    "study_name: str | None\n",
    "study_index: int | None\n",
    "for (\n",
    "    frame_index,\n",
    "    offset_time,\n",
    "    source_name,\n",
    "    study_name,\n",
    "    study_index,\n",
    ") in timeline_df.iter_rows():\n",
    "    study_name = Study(study_name) if study_name is not None else None\n",
    "\n",
    "    rr.set_time_sequence(f\"{source_name}_index\", frame_index)\n",
    "    rr.set_time_seconds(\"capture_time\", offset_time.total_seconds())\n",
    "\n",
    "    if (\n",
    "        webcam_paths is None\n",
    "        and frame_index == 0\n",
    "        and study_name is not None\n",
    "        and study_index is not None\n",
    "    ):\n",
    "        webcam_paths = iter(\n",
    "            p.get_webcam_video_paths(study=study_name, index=study_index)\n",
    "        )\n",
    "\n",
    "    if webcam_paths is not None and webcam_cap is None and frame_index == 0:\n",
    "        webcam_path = next(webcam_paths, None)\n",
    "        if webcam_path is not None:\n",
    "            res = re.search(r\"\\((\\d+)\\)\", webcam_path.name)\n",
    "            if res is not None:\n",
    "                webcam_aux = int(res.group(1))\n",
    "\n",
    "            webcam_cap = cv.VideoCapture(str(webcam_path))\n",
    "        else:\n",
    "            webcam_aux = 0\n",
    "\n",
    "    match source_name:\n",
    "        case \"tobii\":\n",
    "            entry: TobiiEntry = p.tobii_gaze_predictions.row(frame_index, named=True)\n",
    "\n",
    "            for eye in (\"left\", \"right\"):\n",
    "                if entry[f\"{eye}_gaze_point_validity\"]:\n",
    "                    x, y = entry[f\"{eye}_gaze_point_on_display_area\"]\n",
    "                    rr.log(\n",
    "                        f\"screen/gazepoint/{eye}/tobii\",\n",
    "                        rr.Points2D(\n",
    "                            [[x * screen_width, y * screen_height]],\n",
    "                            colors=[[0, 0, 255]],\n",
    "                            radii=[1],\n",
    "                        ),\n",
    "                    )\n",
    "                else:\n",
    "                    rr.log(\n",
    "                        f\"screen/gazepoint/{eye}/tobii\",\n",
    "                        rr.Clear(recursive=True),\n",
    "                    )\n",
    "\n",
    "                if (\n",
    "                    entry[f\"{eye}_pupil_validity\"]\n",
    "                    and entry[f\"{eye}_pupil_diameter\"] > 0\n",
    "                ):\n",
    "                    rr.log(\n",
    "                        f\"participant/pupil/{eye}/tobii\",\n",
    "                        rr.Scalar(entry[f\"{eye}_pupil_diameter\"]),\n",
    "                    )\n",
    "                else:\n",
    "                    rr.log(f\"participant/pupil/{eye}/tobii\", rr.Clear(recursive=True))\n",
    "\n",
    "        case \"screen\" if screen_cap is not None:\n",
    "            if frame_index != screen_cap.get(cv.CAP_PROP_POS_FRAMES):\n",
    "                screen_cap.set(cv.CAP_PROP_POS_FRAMES, frame_index)\n",
    "\n",
    "            rr.set_time_sequence(\"screen_index\", frame_index)\n",
    "            rr.set_time_seconds(\n",
    "                \"screen_time\", screen_cap.get(cv.CAP_PROP_POS_MSEC) / 1_000\n",
    "            )\n",
    "\n",
    "            assert p.screen_recording is not None\n",
    "            assert p.screen_offset is not None\n",
    "\n",
    "            success, frame = screen_cap.read()\n",
    "\n",
    "            if not success or frame_index % 4 != 0:\n",
    "                continue\n",
    "\n",
    "            frame = cv.resize(frame, (screen_width, screen_height))\n",
    "            frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "            rr.log(\"screen\", rr.Image(frame))\n",
    "\n",
    "        case \"webcam\" if webcam_cap is not None:\n",
    "            if frame_index != webcam_cap.get(cv.CAP_PROP_POS_FRAMES):\n",
    "                webcam_cap.set(cv.CAP_PROP_POS_FRAMES, frame_index)\n",
    "\n",
    "            timeline_name = f\"{study_index}_{study_name}_{webcam_aux}\"\n",
    "            rr.set_time_sequence(f\"{timeline_name}_index\", frame_index)\n",
    "            rr.set_time_seconds(\n",
    "                f\"{timeline_name}_time\", webcam_cap.get(cv.CAP_PROP_POS_MSEC) / 1_000\n",
    "            )\n",
    "\n",
    "            success, frame = screen_cap.read()\n",
    "\n",
    "            if not success:\n",
    "                webcam_cap = webcam_cap.release()\n",
    "                webcam_path = None\n",
    "\n",
    "            frame = cv.resize(frame, fx=0.5, fy=0.5)\n",
    "            frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "            rr.log(\"webcam\", rr.Image(frame))\n",
    "\n",
    "        case \"log\":\n",
    "            entry: LogEntry = p.user_interaction_logs.row(frame_index, named=True)\n",
    "            event_type = entry[\"event\"]\n",
    "\n",
    "            match event_type:\n",
    "                case \"start\" | \"stop\":\n",
    "                    rr.log(\n",
    "                        \"log/event\",\n",
    "                        rr.TextLog(\n",
    "                            f\"recording {event_type} {study_index}/{study_name}/{webcam_aux}\",\n",
    "                            level=rr.TextLogLevel.INFO,\n",
    "                        ),\n",
    "                    )\n",
    "\n",
    "                case \"click\":\n",
    "                    rr.log(\n",
    "                        \"log/event\",\n",
    "                        rr.TextLog(\"mouse click\", level=rr.TextLogLevel.DEBUG),\n",
    "                    )\n",
    "\n",
    "                case \"scroll\":\n",
    "                    rr.log(\n",
    "                        \"log/event\",\n",
    "                        rr.TextLog(\"mouse scroll\", level=rr.TextLogLevel.TRACE),\n",
    "                    )\n",
    "\n",
    "                case \"mouse\":\n",
    "                    rr.log(\n",
    "                        \"log/event\",\n",
    "                        rr.TextLog(\"mouse move\", level=rr.TextLogLevel.TRACE),\n",
    "                    )\n",
    "                    rr.log(\n",
    "                        \"screen/mouse\",\n",
    "                        rr.Points2D(\n",
    "                            [\n",
    "                                [\n",
    "                                    entry[\"screen_x\"] / screen_scale_factor,\n",
    "                                    entry[\"screen_y\"] / screen_scale_factor,\n",
    "                                ]\n",
    "                            ],\n",
    "                            colors=[(255, 255, 0)],\n",
    "                            radii=[1],\n",
    "                        ),\n",
    "                    )\n",
    "\n",
    "# end of logging\n",
    "if screen_cap is not None:\n",
    "    screen_cap.release()\n",
    "\n",
    "if webcam_cap is not None:\n",
    "    webcam_cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
